#Time and Space Complexity
Time and space complexity are fundamental concepts in computer science, particularly in the analysis of algorithms.
They help determine the efficiency of an algorithm in terms of the time it takes to complete and the memory it uses.

#Time Complexity
Time complexity measures the amount of time an algorithm takes to complete as a function of the length of the input.
It's often expressed using Big O notation, which describes the upper bound of an algorithm's running time.

#Common Time Complexities:

1. O(1) - Constant Time:
The running time is constant and does not change with the size of the input.
Example: Accessing an array element by index.

2. O(log n) - Logarithmic Time:
The running time increases logarithmically as the input size increases.
Example: Binary search.

3. O(n) - Linear Time:
The running time increases linearly with the size of the input.
Example: Iterating through an array.

4.O(n log n) - Linearithmic Time:
The running time increases linearly with a logarithmic factor.
Example: Merge sort, quicksort (average case).

5.O(n^2) - Quadratic Time:
The running time increases quadratically with the size of the input.
Example: Bubble sort, selection sort.

6.O(2^n) - Exponential Time:
The running time doubles with each additional element in the input.
Example: Solving the traveling salesman problem using brute force.

8.O(n!) - Factorial Time:
The running time grows factorially with the size of the input.
Example: Solving the traveling salesman problem using brute force.
